# ULLALA_JOB_DEV

**Welcome to ULLALA_좝뎁~!**

JOB_DEV은 웹에서 특정 키워드로 채용 정보를 검색하여 사용자에게 제공하는 간단한 웹 애플리케이션입니다. 이 프로젝트는 Flask를 기반으로 구축되었으며, `web3.career`와 `berlinstartupjobs.com` 두 개의 사이트에서 채용 정보를 스크래핑합니다.

## 프로젝트 구조

```
JOB_DEV_ULLALA/
├── extractors/
│   ├── berlinstart.py
│   └── web3career.py
├── templates/
│   ├── home.html
│   └── search.html
├── file.py
├── main.py
└── README.md
```

### 파일 및 디렉터리 설명

- **`extractors/`**: 웹 스크래핑 로직이 포함된 모듈들이 위치한 디렉터리입니다.
  - `berlinstart.py`: `berlinstartupjobs.com`에서 채용 정보를 스크래핑하는 코드가 포함되어 있습니다.
  - `web3career.py`: `web3.career`에서 채용 정보를 스크래핑하는 코드가 포함되어 있습니다.

- **`templates/`**: Flask 애플리케이션에서 사용하는 HTML 템플릿들이 위치한 디렉터리입니다.
  - `home.html`: 사용자가 검색 키워드를 입력할 수 있는 메인 페이지입니다.
  - `search.html`: 검색된 채용 정보를 보여주는 결과 페이지입니다.

- **`file.py`**: 검색된 채용 정보를 CSV 파일로 저장하는 로직이 포함되어 있습니다.

- **`main.py`**: Flask 애플리케이션의 메인 파일로, 라우팅 및 백엔드 로직을 처리합니다.

## 설치 및 실행

### 1. Replit에서 Fork

현재 사이트에서 Fork 를 통해 사용할 수 있습니다.

### 2. 서버 실행

Fork한 후 Replit에서 `main.py` 파일을 실행하세요.

### 3. 웹 애플리케이션 사용

서버가 실행되면, Replit에서 제공하는 웹 URL을 통해 애플리케이션에 접속할 수 있습니다.

## 주요 기능

### 1. 키워드 기반 채용 정보 검색

메인 페이지에서 사용자가 입력한 키워드를 기반으로 `web3.career`와 `berlinstartupjobs.com`에서 관련 채용 정보를 수집합니다.

### 2. 실시간 진행 상황 표시

검색이 진행되는 동안, 로딩 화면에서 실시간으로 스크래핑된 작업 수를 보여줍니다.

### 3. 검색 결과 확인 및 데이터 내보내기

검색이 완료되면 결과 페이지에서 채용 정보를 확인할 수 있으며, "Extract Data (CSV)" 버튼을 통해 CSV 파일로 다운로드할 수 있습니다.

## UI 관련 특징

### 1. 사이버펑크 스타일의 디자인

전체 UI는 어두운 배경과 네온 그린 색상을 사용하여 사이버펑크 스타일로 디자인되었습니다. 이 스타일은 미래지향적인 느낌을 주며, 애플리케이션의 기술적인 기능과 잘 어울립니다.

### 2. 실시간 애니메이션

- **로딩 애니메이션**: 사용자가 검색을 시작하면, 스크래핑이 진행되는 동안 로딩 애니메이션이 표시됩니다. 회전하는 원형 로딩 애니메이션과 함께 현재까지 스크래핑된 작업 수가 실시간으로 업데이트되어 표시됩니다.
- **배경 애니메이션**: 메인 페이지와 검색 결과 페이지에서는 배경에 마트릭스 스타일의 문자 비가 내리는 애니메이션이 적용되어 있습니다. 이는 전체적인 분위기를 더욱 강화하며, 사용자에게 시각적으로 흥미로운 경험을 제공합니다.

### 3. 반응형 디자인

애플리케이션은 반응형으로 설계되어 있어, 다양한 해상도의 디바이스에서도 최적화된 화면을 제공합니다. 테이블 레이아웃은 사용자의 화면 크기에 맞춰 자동으로 조정되며, 필요시 좌우 스크롤이 가능하도록 설계되었습니다.

### 4. 직관적인 인터페이스

- **검색창**: 사용자가 직관적으로 키워드를 입력하고 검색을 시작할 수 있도록 간단하고 명료한 인터페이스를 제공합니다.
- **결과 테이블**: 검색된 채용 정보를 테이블 형식으로 제공하여, 사용자가 쉽게 정보를 비교하고 필요한 데이터를 추출할 수 있습니다.

## 파일 상세 설명

### 1. `main.py`

- **`/` (홈)**: 메인 페이지(`home.html`)를 렌더링합니다.
- **`/search` (검색)**: 사용자가 입력한 키워드를 바탕으로 웹 스크래핑을 수행하고, 결과를 `search.html`에 전달합니다.
- **`/export` (데이터 내보내기)**: 검색된 채용 정보를 CSV 파일로 저장하고 다운로드합니다.

### 2. `berlinstart.py`

`berlinstartupjobs.com`에서 특정 키워드로 검색된 채용 정보를 스크래핑합니다. 각 채용 정보에는 직책, 회사, 링크, 기술 스택이 포함됩니다.

### 3. `web3career.py`

`web3.career`에서 특정 키워드로 검색된 채용 정보를 스크래핑합니다. 이 모듈은 페이지네이션을 처리하여 여러 페이지에서 데이터를 수집하며, 직책, 회사, 급여, 기술 스택 등의 정보를 수집합니다.

### 4. `file.py`

검색된 채용 정보를 CSV 파일로 저장하는 함수가 포함되어 있습니다.

### 5. `home.html`

애플리케이션의 메인 페이지로, 사용자가 검색 키워드를 입력하고 검색을 시작할 수 있는 인터페이스를 제공합니다.

### 6. `search.html`

검색 결과를 테이블 형식으로 표시하는 페이지입니다. 사용자는 이 페이지에서 "Extract Data (CSV)" 버튼을 통해 검색 결과를 CSV 파일로 다운로드할 수 있습니다.

## 기여 방법

프로젝트 관련 기여 또는 소통하고 싶다면, 노마드 디스코드에서 @ullaladavid 로 DM 주세요. 언제든 환영합니다!

## 라이선스

이 프로젝트는 MIT 라이선스 하에 배포됩니다. 자유롭게 사용하고 수정하세요.